{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e325401",
   "metadata": {},
   "source": [
    "# AI/Machine Learning Intern Challenge: Simple Content-Based Recommendation\n",
    "By Josh Houlding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c26b0e",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "<b>Dataset Chosen:</b> [Movies dataset details | Kaggle](https://www.kaggle.com/datasets/sachinkumar62/movies-details) <br>\n",
    "<b>Description from Kaggle Page:</b> \"This dataset contains information on 8,551 movies, including titles, release dates, popularity scores, and user ratings. It features vote counts and average ratings, making it useful for analyzing top-rated films and audience preferences. The dataset also includes movie overviews, providing a brief summary of each film. Ideal for recommendation systems, trend analysis, and sentiment studies in the film industry.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d8691",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "ac19b5f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19404</td>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>Raj is a rich, carefree, happy-go-lucky second...</td>\n",
       "      <td>1995-10-20</td>\n",
       "      <td>18.433</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>724089</td>\n",
       "      <td>Gabriel's Inferno Part II</td>\n",
       "      <td>Professor Gabriel Emerson finally learns the t...</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>8.439</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>65.570</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>63.277</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>761053</td>\n",
       "      <td>Gabriel's Inferno Part III</td>\n",
       "      <td>The final part of the film adaption of the ero...</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>26.691</td>\n",
       "      <td>8.7</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                        title  \\\n",
       "0           0   19404  Dilwale Dulhania Le Jayenge   \n",
       "1           1  724089    Gabriel's Inferno Part II   \n",
       "2           2     278     The Shawshank Redemption   \n",
       "3           3     238                The Godfather   \n",
       "4           4  761053   Gabriel's Inferno Part III   \n",
       "\n",
       "                                            overview release_date  popularity  \\\n",
       "0  Raj is a rich, carefree, happy-go-lucky second...   1995-10-20      18.433   \n",
       "1  Professor Gabriel Emerson finally learns the t...   2020-07-31       8.439   \n",
       "2  Framed in the 1940s for the double murder of h...   1994-09-23      65.570   \n",
       "3  Spanning the years 1945 to 1955, a chronicle o...   1972-03-14      63.277   \n",
       "4  The final part of the film adaption of the ero...   2020-11-19      26.691   \n",
       "\n",
       "   vote_average  vote_count  \n",
       "0           8.7        2763  \n",
       "1           8.7        1223  \n",
       "2           8.7       18637  \n",
       "3           8.7       14052  \n",
       "4           8.7         773  "
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and view data\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eff21d",
   "metadata": {},
   "source": [
    "The only columns we need are the movie titles and descriptions, so we can drop everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "a29a8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataframe down to only necessary columns\n",
    "df = df[[\"title\", \"overview\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2283f08",
   "metadata": {},
   "source": [
    "The README.md file on this challenge's GitHub repository also says this:\n",
    "\n",
    ">Make sure the dataset is easy to handle (maybe 100–500 rows) so the solution remains quick to implement and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "58a71317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 8551\n"
     ]
    }
   ],
   "source": [
    "# Show dataset shape\n",
    "print(f\"Number of entries: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79fa95",
   "metadata": {},
   "source": [
    "Our dataset is too big. Let's take a random sample of 500 rows to ensure speedy performance for our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "6212b406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 500\n"
     ]
    }
   ],
   "source": [
    "# Take random sample of 500 entries\n",
    "df = df.sample(500, random_state=42)\n",
    "\n",
    "# Show new entry count\n",
    "print(f\"Number of entries: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b971682",
   "metadata": {},
   "source": [
    "## Handling duplicates and missing values\n",
    "This will improve the accuracy of our model's recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "d22ee1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "8bb268df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "overview    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing value count by column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc03b1",
   "metadata": {},
   "source": [
    "The missing value count is so small that we can just drop rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "3b540520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af11c6",
   "metadata": {},
   "source": [
    "It's also a good idea to save a copy of the dataframe before processing, so we can access the data in its original form whenever needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "96b13f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of dataframe\n",
    "unprocessed_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e2d090",
   "metadata": {},
   "source": [
    "## Lowercasing the movie overviews\n",
    "Setting all letters to lowercase in the movie descriptions ensures consistency, improving the accuracy of similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "b6d5057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set descriptions to lowercase\n",
    "df[\"overview\"] = df[\"overview\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e57b4c",
   "metadata": {},
   "source": [
    "## Remove punctuation and stopwords\n",
    "Punctuation includes characters like periods, apostrophes, colons, etc., and stopwords are common words like \"the\", \"a\", \"and\", etc. that aren't useful for recommendation systems. Removing both of them streamlines performance and improves accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "3611b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Remove punctuation from overviews\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(lambda x: x.translate(translator))\n",
    "\n",
    "# Remove stopwords from overviews\n",
    "stop_words = ENGLISH_STOP_WORDS  # Use scikit-learn's stop words\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea43d04",
   "metadata": {},
   "source": [
    "## Stemming the text\n",
    "Stemming involves reducing words to their root or base form (\"stem\"). For example, \"running\", \"runs\", and \"ran\" would all be stemmed to \"run\". Like with the other preprocessing steps, this improves matching and makes the model more efficient.\n",
    "\n",
    "We will use a Porter Stemmer here, which is a very aggressive form of stemmer that often produces stems that don't look like recognizable words. However, these odd-looking stems are highly useful to recommendation systems, which is why this type of stemmer is so useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "2c2291a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Perform stemming on overviews\n",
    "stemmer = PorterStemmer()\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(\n",
    "    lambda x: \" \".join([stemmer.stem(word) for word in x.split()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32348c03",
   "metadata": {},
   "source": [
    "## Final text dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "4721cf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389    naiv busi graduat instal presid manufactur com...\n",
       "5048    year 2056 epidem organ failur devast planet me...\n",
       "3133    shortli david abbott move new san francisco di...\n",
       "5955    covert secur compani vanguard hope surviv acco...\n",
       "625     jake blue just releas prison put old band togt...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show final text dataframe\n",
    "df[\"overview\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb026a56",
   "metadata": {},
   "source": [
    "## Vectorize the text\n",
    "We need to vectorize the text into a numeric form so the model can analyze it, and we will do this with TF-IDF, a rigorous and often-used algorithm. It converts the text data into a sparse matrix where each row represents a movie, and each column represents a word in the vocabulary of the text data. This enables the model to quantify the importance of words in each movie's description, and thus understand which movies are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "80676f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer() \n",
    "tfidf_matrix = tfidf.fit_transform(df[\"overview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "0ed3d2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<498x4478 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11826 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show info about TF-IDF matrix\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ede3d",
   "metadata": {},
   "source": [
    "We have a sparse matrix with 498 rows, one for each movie in the dataframe, and 4,478 columns for all the unique words found in the descriptions of the movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8722af4",
   "metadata": {},
   "source": [
    "## Taking user input and providing recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "5fb9d46f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You provided us with the following query: \"I like action movies set in space\"\n",
      "This is how many recommendations you wanted: 5\n",
      "Here are 5 movies we think you'll love. \n",
      "\n",
      "Movie 1: \"Gattaca\". Similarity score: 0.2324916639956013.\n",
      "Movie description: \"In a future society in the era of indefinite eugenics, humans are set on a life course depending on their DNA. Young Vincent Freeman is born with a condition that would prevent him from space travel, yet is determined to infiltrate the GATTACA space program.\" \n",
      "\n",
      "Movie 2: \"The Cheetah Girls: One World\". Similarity score: 0.21330124631580724.\n",
      "Movie description: \"Chanel, Dorinda, and Aqua, are off to India to star in a Bollywood movie. But when there they discover that they will have to compete against each other to get the role in the movie. Will the Cheetah's break up again?\" \n",
      "\n",
      "Movie 3: \"The Transporter Refueled\". Similarity score: 0.21256302560184892.\n",
      "Movie description: \"The fast-paced action movie is again set in the criminal underworld in France, where Frank Martin is known as The Transporter, because he is the best driver and mercenary money can buy. In this installment, he meets Anna and they attempt to take down a group of ruthless Russian human traffickers who also have kidnapped Frank’s father.\" \n",
      "\n",
      "Movie 4: \"The Village\". Similarity score: 0.17445331354748186.\n",
      "Movie description: \"When a willful young man tries to venture beyond his sequestered Pennsylvania hamlet, his actions set off a chain of chilling incidents that will alter the community forever.\" \n",
      "\n",
      "Movie 5: \"Deep Impact\". Similarity score: 0.16773760137379393.\n",
      "Movie description: \"A seven-mile-wide space rock is hurtling toward Earth, threatening to obliterate the planet. Now, it's up to the president of the United States to save the world. He appoints a tough-as-nails veteran astronaut to lead a joint American-Russian crew into space to destroy the comet before impact. Meanwhile, an enterprising reporter uses her smarts to uncover the scoop of the century.\" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to preprocess user query\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    words = text.split()\n",
    "    stop_words = ENGLISH_STOP_WORDS\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def provide_recommendations(user_query, num_recommendations):\n",
    "    \n",
    "    print(f\"You provided us with the following query: \\\"{user_query}\\\"\")\n",
    "    print(f\"This is how many recommendations you wanted: {num_recommendations}\")\n",
    "    \n",
    "    # Process user query into TF-IDF vector/matrix\n",
    "    processed_user_query = preprocess_text(user_query)\n",
    "    user_query_vector = tfidf.transform([processed_user_query])\n",
    "    \n",
    "    # Calculate similarity scores for all movies\n",
    "    similarity_scores = cosine_similarity(user_query_vector, tfidf_matrix)\n",
    "    \n",
    "    # Get the top n recommendations and their similarity scores\n",
    "    movie_indices = similarity_scores.argsort()[0][::-1][:num_recommendations]\n",
    "    recommended_movies = []\n",
    "    for i in movie_indices:\n",
    "        movie_title = df['title'].iloc[i]\n",
    "        similarity_score = similarity_scores[0][i]\n",
    "        recommended_movies.append((movie_title, similarity_score))\n",
    "        \n",
    "    # Get the overviews of the movies\n",
    "    recommended_movie_descriptions = unprocessed_df.iloc[movie_indices]\n",
    "\n",
    "    print(f\"Here are {num_recommendations} movies we think you'll love. \\n\")\n",
    "\n",
    "    # Show movie titles and similarity scores\n",
    "    for i in range(0, num_recommendations):\n",
    "        print(f\"Movie {i + 1}: \\\"{recommended_movies[i][0]}\\\". Similarity score: {recommended_movies[i][1]}.\")\n",
    "        movie_description = recommended_movie_descriptions.iloc[i][\"overview\"]\n",
    "        print(f\"Movie description: \\\"{movie_description}\\\" \\n\")\n",
    "\n",
    "provide_recommendations(\"I like action movies set in space\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
