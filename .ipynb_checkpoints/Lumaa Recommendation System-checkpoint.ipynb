{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e325401",
   "metadata": {},
   "source": [
    "# AI/Machine Learning Intern Challenge: Simple Content-Based Recommendation\n",
    "By Josh Houlding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a33a92",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "<b>Dataset Chosen:</b> [Movies dataset details | Kaggle](https://www.kaggle.com/datasets/sachinkumar62/movies-details) <br>\n",
    "<b>Description from Kaggle Page:</b> \"This dataset contains information on 8,551 movies, including titles, release dates, popularity scores, and user ratings. It features vote counts and average ratings, making it useful for analyzing top-rated films and audience preferences. The dataset also includes movie overviews, providing a brief summary of each film. Ideal for recommendation systems, trend analysis, and sentiment studies in the film industry.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b10818",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2696d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19404</td>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>Raj is a rich, carefree, happy-go-lucky second...</td>\n",
       "      <td>1995-10-20</td>\n",
       "      <td>18.433</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>724089</td>\n",
       "      <td>Gabriel's Inferno Part II</td>\n",
       "      <td>Professor Gabriel Emerson finally learns the t...</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>8.439</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>278</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>65.570</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>238</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>63.277</td>\n",
       "      <td>8.7</td>\n",
       "      <td>14052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>761053</td>\n",
       "      <td>Gabriel's Inferno Part III</td>\n",
       "      <td>The final part of the film adaption of the ero...</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>26.691</td>\n",
       "      <td>8.7</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id                        title  \\\n",
       "0           0   19404  Dilwale Dulhania Le Jayenge   \n",
       "1           1  724089    Gabriel's Inferno Part II   \n",
       "2           2     278     The Shawshank Redemption   \n",
       "3           3     238                The Godfather   \n",
       "4           4  761053   Gabriel's Inferno Part III   \n",
       "\n",
       "                                            overview release_date  popularity  \\\n",
       "0  Raj is a rich, carefree, happy-go-lucky second...   1995-10-20      18.433   \n",
       "1  Professor Gabriel Emerson finally learns the t...   2020-07-31       8.439   \n",
       "2  Framed in the 1940s for the double murder of h...   1994-09-23      65.570   \n",
       "3  Spanning the years 1945 to 1955, a chronicle o...   1972-03-14      63.277   \n",
       "4  The final part of the film adaption of the ero...   2020-11-19      26.691   \n",
       "\n",
       "   vote_average  vote_count  \n",
       "0           8.7        2763  \n",
       "1           8.7        1223  \n",
       "2           8.7       18637  \n",
       "3           8.7       14052  \n",
       "4           8.7         773  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and view data\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da943da",
   "metadata": {},
   "source": [
    "The only columns we need are the movie titles and descriptions, so we can drop everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05cdf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df[[\"title\", \"overview\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e246f9e",
   "metadata": {},
   "source": [
    "The README.md file on this challenge's GitHub repository also says this:\n",
    "\n",
    ">Make sure the dataset is easy to handle (maybe 100â€“500 rows) so the solution remains quick to implement and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1017b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 8551\n"
     ]
    }
   ],
   "source": [
    "# Show dataset shape\n",
    "print(f\"Number of entries: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cb589",
   "metadata": {},
   "source": [
    "Let's take a random sample of 500 rows to ensure speedy performance for our model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b07d6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 500\n"
     ]
    }
   ],
   "source": [
    "# Take random sample of 500 entries\n",
    "df = df.sample(500, random_state=42)\n",
    "\n",
    "# Show new entry count\n",
    "print(f\"Number of entries: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049da0c4",
   "metadata": {},
   "source": [
    "## Handling duplicates and missing values\n",
    "This will improve the accuracy of our model's recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ab763cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4887238f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title       0\n",
       "overview    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing value count by column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df51685d",
   "metadata": {},
   "source": [
    "The missing value count is so small that we can just drop rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "00c704e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2e2dc",
   "metadata": {},
   "source": [
    "## Lowercasing the movie overviews\n",
    "Setting all letters to lowercase in the movie descriptions ensures consistency, improving the accuracy of similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "960fc372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set descriptions to lowercase\n",
    "df[\"overview\"] = df[\"overview\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137aa781",
   "metadata": {},
   "source": [
    "## Remove punctuation and stopwords\n",
    "Punctuation includes characters like periods, apostrophes, colons, etc., and stopwords are common words like \"the\", \"a\", \"and\", etc. that aren't useful for recommendation systems. Removing both of them streamlines performance and improves accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e344dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# Remove punctuation from overviews\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(lambda x: x.translate(translator))\n",
    "\n",
    "# Remove stopwords from overviews\n",
    "stop_words = ENGLISH_STOP_WORDS  # Use scikit-learn's stop words\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in stop_words])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2d36af",
   "metadata": {},
   "source": [
    "## Stemming the text\n",
    "Stemming involves reducing words to their root or base form (\"stem\"). For example, \"running\", \"runs\", and \"ran\" would all be stemmed to \"run\". Like with the other preprocessing steps, this improves matching and makes the model more efficient.\n",
    "\n",
    "We will use a Porter Stemmer here, which is a very aggressive form of stemmer that often produces stems that don't look like recognizable words. However, these odd-looking stems are highly useful to recommendation systems, which is why this type of stemmer is so useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64d57a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Perform stemming on overviews\n",
    "stemmer = PorterStemmer()\n",
    "df[\"overview\"] = df[\"overview\"].astype(str).apply(\n",
    "    lambda x: \" \".join([stemmer.stem(word) for word in x.split()])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64986b",
   "metadata": {},
   "source": [
    "## Final text dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1ed220b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2389    naiv busi graduat instal presid manufactur com...\n",
      "5048    year 2056 epidem organ failur devast planet me...\n",
      "3133    shortli david abbott move new san francisco di...\n",
      "5955    covert secur compani vanguard hope surviv acco...\n",
      "625     jake blue just releas prison put old band togt...\n",
      "Name: overview, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"overview\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d998b",
   "metadata": {},
   "source": [
    "## Vectorize the text\n",
    "We need to vectorize the text into a numeric form so the model can analyze it, and we will do this with TF-IDF, a rigorous and often-used algorithm. It converts the text data into a sparse matrix where each row represents a movie, and each column represents a word in the vocabulary of the text data. This enables the model to quantify the importance of words in each movie's description, and thus understand which movies are similar to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3af7b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "tfidf = TfidfVectorizer() \n",
    "tfidf_matrix = tfidf.fit_transform(df[\"overview\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe6977dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<498x4478 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 11826 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show info about TF-IDF matrix\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35cf351",
   "metadata": {},
   "source": [
    "We have a sparse matrix with 498 rows, one for each movie in the dataframe, and 4,478 columns for all the unique words found in the descriptions of the movies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
